<!doctype html>
<html lang="pt-BR">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>YOLOv10 Document Layout Detection</title>
    </head>
    <body style="text-align: center; background: #111; color: #fff">
        <h2>YOLOv10 Document Layout Detection</h2>
        <canvas id="canvas"></canvas>

        <script type="module">
            import {
                AutoModel,
                AutoProcessor,
                RawImage,
                env,
            } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.7.5";

            env.backends.onnx.wasm.numThreads = 8;
            env.backends.onnx.wasm.simd = true;
            env.backends.onnx.backend = "wasm";

            async function main() {
                const model = await AutoModel.from_pretrained(
                    "Oblix/yolov10m-doclaynet_ONNX_document-layout-analysis",
                    {
                        dtype: "fp32",
                    },
                );
                const processor = await AutoProcessor.from_pretrained(
                    "Oblix/yolov10m-doclaynet_ONNX_document-layout-analysis",
                );

                const t0 = performance.now();

                const url = "sample.jpg";
                const image = await RawImage.read(url);
                const { pixel_values, reshaped_input_sizes } = await processor(image);
                const { output0 } = await model({ images: pixel_values });

                const t1 = performance.now();
                const detectionTime = (t1 - t0).toFixed(2);
                console.log(`Tempo de detecção: ${detectionTime} ms`);

                const predictions = output0.tolist()[0];
                const threshold = 0.35;
                const [newHeight, newWidth] = reshaped_input_sizes[0];
                const [xs, ys] = [image.width / newWidth, image.height / newHeight];

                // Criar canvas e desenhar imagem
                const canvas = document.getElementById("canvas");
                const ctx = canvas.getContext("2d");
                canvas.width = image.width;
                canvas.height = image.height;

                // Desenhar a imagem
                const htmlImage = new Image();
                htmlImage.src = url;
                await new Promise((resolve) => {
                    htmlImage.onload = resolve;
                });
                ctx.drawImage(htmlImage, 0, 0, image.width, image.height);

                // Map de classes (opcional, baseado no DocLayNet)
                const classes = [
                    "caption",
                    "footnote",
                    "formula",
                    "list-item",
                    "page-footer",
                    "page-header",
                    "picture",
                    "section-header",
                    "table",
                    "text",
                ];

                // Desenhar as detecções
                ctx.lineWidth = 2;
                ctx.font = "16px sans-serif";

                for (const [xmin, ymin, xmax, ymax, score, id] of predictions) {
                    if (score < threshold) continue;

                    const x1 = xmin * xs;
                    const y1 = ymin * ys;
                    const x2 = xmax * xs;
                    const y2 = ymax * ys;

                    const w = x2 - x1;
                    const h = y2 - y1;

                    ctx.strokeStyle = "lime";
                    ctx.fillStyle = "lime";
                    ctx.strokeRect(x1, y1, w, h);

                    const label = `${classes[id] || id} (${(score * 100).toFixed(1)}%)`;
                    const textWidth = ctx.measureText(label).width;
                    ctx.fillRect(x1, y1 - 20, textWidth + 6, 20);
                    ctx.fillStyle = "black";
                    ctx.fillText(label, x1 + 3, y1 - 5);
                }
            }

            main();
        </script>
    </body>
</html>
